{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TSE - Group 19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN36jKXIUCaq6bqHEBhackW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarryBurgin/TSE-Assignment3/blob/main/TSE_Group_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes** <br>\n",
        "Would be good if someone could upload the data to colab using kaggle. <br>\n",
        "I think u can upload data using its URL"
      ],
      "metadata": {
        "id": "lun3-kDtJxvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up**<br>\n",
        "Import all relevant libraries"
      ],
      "metadata": {
        "id": "d4Wx5RZysUPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CPTAZIunsHZ9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "## Used to read csv data file\n",
        "from google.colab import files\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create data tensors** <br>\n",
        "Load csv file and clean data"
      ],
      "metadata": {
        "id": "R0Lf4br2sqZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to create a list of reviews and a list of sentiments (+ve/-ve)\n",
        "def listCreation(inputData, resultData):\n",
        "    #Opens the csv file\n",
        "    fileName = open('IMDB Dataset.csv', 'r', encoding='utf-8')\n",
        "    file = csv.DictReader(fileName)\n",
        "    #Iterates each row then appends dataset\n",
        "    for col in file:\n",
        "        inputData.append(col['review'])\n",
        "        if col['sentiment'] == 'positive':\n",
        "          resultData.append(1)\n",
        "        elif col['sentiment'] == 'negative':\n",
        "          resultData.append(0)\n",
        "        else:\n",
        "          resultData.append(\"findMe\")                          \n",
        "\n",
        "def dataCleanup(inputData):\n",
        "    #Iterates through the review\n",
        "    for i in range(len(inputData)):\n",
        "      #Replaces any text between <> with a blank\n",
        "      inputData[i] = re.sub('<.*?>', '', inputData[i])"
      ],
      "metadata": {
        "id": "nG6divHBswQ_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenise reviews** <br>\n",
        "Use of libraries used here is not suggested"
      ],
      "metadata": {
        "id": "ykP7wUBhY6Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenising the data\n",
        "\n",
        "# token = Tokenizer(lower = True)\n",
        "# token.fit_on_texts(x_train)\n",
        "# x_train = token.texts_to_sequences(x_train)\n",
        "# x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "def tokeniseData(data, Dtype):\n",
        "  if (Dtype == \"train\"):\n",
        "    token.fit_on_texts(data)\n",
        "  data = token.texts_to_sequences(data)\n",
        "  return data"
      ],
      "metadata": {
        "id": "uiHdgGXWY-5f"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limiting word count and adding padding**"
      ],
      "metadata": {
        "id": "NGDs_GPaLZhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Limiting word count and adding padding\n",
        "def paddingData(data, maxWords):\n",
        "  for d in range(len(data)): # Loops through data\n",
        "    if len(data[d]) > maxWords: # If length of data is above max words\n",
        "      data[d] = data[d][0:120] # Take a slice of the list starting from index 0 to 120\n",
        "\n",
        "  for d in range(len(data)): # Loop through review\n",
        "    while len(data[d]) < maxWords: # While the data length is below 120\n",
        "      data[d].append(0) # Append another 0\n",
        "\n",
        "  ## Returns the data with padding\n",
        "  return data"
      ],
      "metadata": {
        "id": "Ho0dG-3ib13G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing data**"
      ],
      "metadata": {
        "id": "ylH-l8hnMmcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reading data into list\n",
        "## Splitting data into train and test sets\n",
        "inputData = []\n",
        "resultData= []\n",
        "\n",
        "listCreation(inputData, resultData)\n",
        "dataCleanup(inputData)\n",
        "\n",
        "\n",
        "## X is review and y is sent\n",
        "## Split into train and test data\n",
        "## random_state set to 0 for testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(inputData, resultData, test_size=0.2, random_state=0) \n",
        "## Could split test data into test and validation"
      ],
      "metadata": {
        "id": "Z7O46riLMo79"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenising data\n",
        "## Tokenising been changed because of func\n",
        "token = Tokenizer(lower = True) ## Token\n",
        "\n",
        "x_train = tokeniseData(x_train, \"train\")\n",
        "x_test = tokeniseData(x_test, \"test\")  "
      ],
      "metadata": {
        "id": "dI2fG6wyMyfs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Limiting word count and adding padding\n",
        "maxWords = 120 # Sets max number of words\n",
        "total_words = len(token.word_index) + 1\n",
        "\n",
        "x_test = paddingData(x_test, maxWords)\n",
        "x_train = paddingData(x_train, maxWords)\n",
        "\n",
        "\n",
        "## Shows that all reviews have same number of words\n",
        "for _ in x_test:\n",
        "  if (len(_) != maxWords):\n",
        "    print(_)\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  if (y_train[i] != 1 and y_train[i] != 0):\n",
        "    print(i, \" \", y_train[i])"
      ],
      "metadata": {
        "id": "T3RSKJF3NI4Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Converting train and test data to tensors\n",
        "x_train = tf.convert_to_tensor(x_train, dtype=tf.int32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int16)\n",
        "x_test = tf.convert_to_tensor(x_test, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.int16)\n",
        "\n",
        "#print(y_train)\n",
        "#print(x_train)"
      ],
      "metadata": {
        "id": "OFYc991OVOE4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create model**"
      ],
      "metadata": {
        "id": "B9SB0YVHhtR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Shows other model with in-built text preprocessing \n",
        "# # Text preprocessing does not need to be done with this model, the inputs just have to be converted to a suitable tensor\n",
        "\n",
        "# # vectorize_layer = layers.TextVectorization(standardize='lower_and_strip_punctuation', max_tokens=total_words, output_mode='int', output_sequence_length=maxWords)\n",
        "# # Call adapt to build the vocabulary.\n",
        "# # vectorize_layer.adapt(x_train)\n",
        "\n",
        "# # EMBED_DIM = 32\n",
        "# # LSTM_OUT = 64\n",
        "\n",
        "# # model = keras.Sequential()\n",
        "# # model.add(vectorize_layer)\n",
        "# # model.add(layers.Embedding(total_words, EMBED_DIM, input_length = maxWords))\n",
        "# # model.add(layers.LSTM(LSTM_OUT, dropout=0.75, recurrent_dropout=0.5, return_sequences=False))\n",
        "# # model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(total_words, EMBED_DIM, input_length = maxWords))\n",
        "model.add(layers.LSTM(LSTM_OUT, dropout=0.75, recurrent_dropout=0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJTbTIx4hr6S",
        "outputId": "624d54d3-8d99-41f2-883b-726154c0ec36"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 120, 32)           3643168   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                24832     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,668,065\n",
            "Trainable params: 3,668,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile model**"
      ],
      "metadata": {
        "id": "w3eVqudUiuzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(\n",
        "#     loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "#     metrics = [\"accuracy\"]\n",
        "#     )\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "ZIdyjBrtiyf-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Zone**"
      ],
      "metadata": {
        "id": "WDssIDG0NY2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, verbose = 1)"
      ],
      "metadata": {
        "id": "thfbkf6tNa6f",
        "outputId": "115e645a-f333-4f66-9a8e-5b585cb5011a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 92s 284ms/step - loss: 0.5728 - accuracy: 0.6733\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 89s 285ms/step - loss: 0.3408 - accuracy: 0.8595\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 89s 283ms/step - loss: 0.2647 - accuracy: 0.8955\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 89s 284ms/step - loss: 0.2095 - accuracy: 0.9200\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 88s 283ms/step - loss: 0.1711 - accuracy: 0.9370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ea0ad6b50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 128, verbose = 2)\n",
        "## Epochs = 5, batch_size = 128\n",
        "## 0.84 accuracy with no dropout\n",
        "## 0.86 with dropout=0.75  \n",
        "## 0.8600 with dropout=0.75, recurrent_dropout=0.5\n",
        "\n",
        "## Increaced size of test cases"
      ],
      "metadata": {
        "id": "cXnp6r11kOZ4",
        "outputId": "de1779ed-4ebb-4c2e-f7e9-c0ace4aa5e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 - 3s - loss: 0.4135 - accuracy: 0.8542 - 3s/epoch - 40ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41351762413978577, 0.854200005531311]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding predictions**"
      ],
      "metadata": {
        "id": "tUmpMnPcFO-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "## Positive \n",
        "reviews.append(\"Fantastic Film\")\n",
        "## Negative\n",
        "reviews.append(\"I have no idea who wrote this, but god it feels like it's meant for kids. Not scary, all over the place with irrelevant stories, boring from beginning to ...end? Could not tell, turned it off after the witch flew across town to visit the little girl. Don't care what happens next.\")\n",
        "reviews.append(\"Yikes. Doctor sleep is a fitting name cuz you're gonna wanna by the time this movies finally over. It feels so much longer than it is. It's corny, cringy, the dialogue is bad, the characters are not believable, the story is predictable and goofy as hell. It's critically just not a good film. But even worse, it's not an interesting or entertaining one.\")\n",
        "reviews.append(\"Is it me? I thought this Film was so slow and mixed up I was so bored i fell asleep what a waist of time..Stanley Kubrick would be turning in his grave at this one..I should have painted a door and watched it dry that would've been more enjoyable.\")\n",
        "## Poitive\n",
        "reviews.append(\"Ok first of all I never read the books I just go to the movies so I never knew until I saw this movie what the shining was and this movie filled in all the gaps that I didn't understand from the first one and I thought it was pretty good it did make me jump a few times in my seat which is really hard to do considering how desensitized I am from seeing so many I don't think people are giving this one enough credit by going to the theater to see it but I'm sure it will do better in video sales.\")\n",
        "reviews.append(\"I was saving this film aside for quite a while, because I assumed it's just another horror movie (I don't scare easily so I find the horror genre kinda boring), and I finally watched it yesterday... well, the truth is: it's more fantasy than horror, and I was surprised by how brilliant & enjoyable it was!\")\n",
        "\n",
        "\n",
        "\n",
        "reviews = tokeniseData(reviews, \"test\")\n",
        "reviews = paddingData(reviews, maxWords)\n",
        "reviews = tf.convert_to_tensor(reviews, dtype=tf.int32)\n",
        "\n",
        "\n",
        "model.predict(reviews)"
      ],
      "metadata": {
        "id": "7tHQSKYyFST-",
        "outputId": "d1659bf5-b83f-451a-9d85-a95e19d5962f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.94867885],\n",
              "       [0.00758743],\n",
              "       [0.02491516],\n",
              "       [0.01094967],\n",
              "       [0.8399501 ],\n",
              "       [0.9804402 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}